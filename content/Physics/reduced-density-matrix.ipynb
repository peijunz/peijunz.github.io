{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduced density matrix and partial trace\n",
    "+ date: 2017-05-03\n",
    "+ tags: python\n",
    "+ summary: The reduced matrix is defined as the partial trace of the density matrix. In linear algebra and functional analysis, the partial trace is a generalization of the trace. Whereas the trace is a scalar valued function on operators, the partial trace is an operator-valued function. The partial trace has applications in quantum information and decoherence which is relevant for quantum measurement and thereby to the decoherent approaches to interpretations of quantum mechanics, including consistent histories and the relative state interpretation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "#ignore\n",
    "%pylab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduced density matrix\n",
    "Suppose we have two quantum systems $a, b$, with dimension $N_a, N_b$ respectively. Then the Hilbert space of $a+b$ is of dimension $N=N_aN_b$. Suppose we have a density matrix\n",
    "$$\\hat\\rho=\\sum_{i,j}\\rho_{ij}\\lvert i\\rangle \\langle j\\rvert=\\sum_{i,j,k,l}\\rho_{ijkl}\\lvert i\\rangle_a\\lvert j\\rangle_b \\langle k\\rvert_a\\langle l\\rvert_b$$\n",
    "\n",
    "Then the reduced density matrix of $a$ is defined as\n",
    "$$\\hat\\rho_a=\\mathrm{tr}_b\\hat\\rho=\\sum_i \\langle i\\rvert_b\\hat\\rho\\lvert i\\rangle_b$$\n",
    "\n",
    "i.e. reduced density matrix problem is equivalent to partial trace problem.\n",
    "\n",
    "### Tensor\n",
    "In fact, if we take $\\hat\\rho$ as a 4-tensor $\\rho_{ijkl}$, then the reduced density matrix is $$\\rho^{(a)}_{ij}=\\delta^{\\mu\\nu}\\rho_{i\\mu k\\nu}$$\n",
    "For simple density matrix $\\rho=\\lvert \\psi\\rangle \\langle \\psi\\rvert$, the reduced matrix is\n",
    "$$\\rho^{(a)}_{ik}=\\delta^{jl}\\rho_{ijkl}=\\delta^{jl}\\psi_{ij}\\psi^+_{lk}=\\sum_i |\\langle i_b\\lvert \\psi\\rangle|^2=[\\psi\\psi^+]_{ik}$$\n",
    "Here we are taking $\\psi$ as an $N_a\\times N_b$ matrix. \n",
    "\n",
    "For general case, if we find decomposition\n",
    "$$\\rho=\\sum_c \\lambda_c\\lvert \\psi_c\\rangle \\langle \\psi_c\\rvert,\\quad \\sum_c \\lambda_c=1$$\n",
    "then we have \n",
    "$$\\rho^{(a)}_{ik}=\\left[\\sum_c\\lambda_c\\psi_c\\psi^+_c\\right]_{ik}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial trace\n",
    "### Computation of partial trace by hand \n",
    "$\\rho$ can be regarded as $N_a\\times N_a$ block matrices $A_{ij}$ with size $N_b\\times N_b$ for each $A_{ij}$.\n",
    "+ Partial trace over $a$ is like summation over block matrices in the diagonal: $\\sum_i A_{ii}$\n",
    "+ Partial trace over $b$ is like tracing over all $A_{ij}$ block matrices in the diagonal: $A_{ij}\\rightarrow \\mathrm{tr}(A_{ij})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compution of partial trace in numpy\n",
    "It seems that there is no partial trace function in numpy, but there is trace(contraction) function for ndarray(tensors). \n",
    "\n",
    "As an example, suppose we have an $N\\times N$ density matrix $\\rho$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0625  0.125   0.1875  0.25  ]\n",
      " [ 0.125   0.1875  0.25    0.3125]\n",
      " [ 0.1875  0.25    0.3125  0.375 ]\n",
      " [ 0.25    0.3125  0.375   0.4375]]\n"
     ]
    }
   ],
   "source": [
    "n1, n2, n=2, 2, 4\n",
    "A=arange(4)[newaxis, :]\n",
    "rho=(1+A+A.transpose())\n",
    "rho=rho/trace(rho)\n",
    "print(rho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can recast it to a tensor with more axes by `.reshape()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rho_tensor=rho.reshape([n1, n2, n1, n2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is contraction:\n",
    "+ Partial trace over $a$ is contraction over axis $0, 2$, which produces $\\rho_b$\n",
    "+ Partial trace over $b$ is contraction over axis $1, 3$, which produces $\\rho_a$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.25,  0.5 ],\n",
       "       [ 0.5 ,  0.75]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace(rho_tensor, axis1=1, axis2=3) #rho_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.375,  0.5  ],\n",
       "       [ 0.5  ,  0.625]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace(rho_tensor, axis1=0, axis2=2) #rho_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
